{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac39918-4a43-4383-884d-80d0f0c91962",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3907a614-9303-4ae8-9965-720b288e7a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab526f5-50ca-4c54-815a-ca0b51882d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Binarize:\n",
    "    def __call__(self, sample):\n",
    "        return torch.bernoulli(sample)\n",
    "\n",
    "transform = Compose([ToTensor()])\n",
    "\n",
    "dataset_train = CIFAR10('./data', train=True, transform=transform, download=True)\n",
    "dataset_test = CIFAR10('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=64, shuffle=True, pin_memory=True, num_workers=4)\n",
    "loader_test = DataLoader(dataset_test, batch_size=64, shuffle=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "loaders = {\n",
    "    'train': loader_train,\n",
    "    'test': loader_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f896a07e-a00a-4d66-822e-9122527e7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "            \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        z = self.sample_latent(mu, sigma)\n",
    "        dec = self.decoder(z)\n",
    "        return dec, mu, sigma\n",
    "    \n",
    "    def sample_latent(self, mu, sigma):\n",
    "        # if self.training:\n",
    "        #     return mu\n",
    "        z = torch.normal(0., 1., size=list(mu.size())).to(self.device)\n",
    "        z = z * sigma + mu\n",
    "        return z\n",
    "    \n",
    "    def sample_data(self, sample_size, sample=None):\n",
    "        if sample is None:\n",
    "            z = torch.normal(0., 1., size=sample_size).to(self.device)\n",
    "        x_sampled = self.decoder(z)\n",
    "        return x_sampled\n",
    "    \n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_dims, noise=nn.Identity()):\n",
    "        super().__init__()\n",
    "        self.noise = noise\n",
    "        self.normalize = nn.BatchNorm2d(img_dims[0])\n",
    "        self.encoder_conv = nn.Sequential(nn.Conv2d(img_dims[0], 32, kernel_size=3, stride=1, padding=1), # 28\n",
    "                                     nn.BatchNorm2d(32), nn.ReLU(), nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # 14\n",
    "                                     nn.BatchNorm2d(64), nn.ReLU(),nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1), # 7\n",
    "                                     nn.BatchNorm2d(64), nn.ReLU(), nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)) # 4\n",
    "        self.encoder_fc = nn.Sequential(nn.Linear(4*4*128, 256), nn.BatchNorm1d(256), nn.ReLU())\n",
    "        self.mu = nn.Linear(256, 256)\n",
    "        self.log_sigma = nn.Linear(256, 256)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        x = self.noise(x)\n",
    "        x = self.encoder_conv(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.encoder_fc(x)\n",
    "        mu = self.mu(x)\n",
    "        log_sigma = self.log_sigma(x)\n",
    "        sigma = torch.log(1 + torch.exp(log_sigma))\n",
    "        return mu, sigma\n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, img_dims):\n",
    "        super().__init__()\n",
    "        self.img_dims = img_dims\n",
    "        flatten_img_dims = np.prod(img_dims)\n",
    "        self.decoder_fc = nn.Sequential(nn.Linear(256, 128*4*4))\n",
    "        self.decoder_conv = nn.Sequential(nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 64, 3, stride=2), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(64, 32, 3, stride=2), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "                                     nn.ConvTranspose2d(32, img_dims[0], 3, stride=1))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_fc(x)\n",
    "        x = x.view(-1, 128, 4, 4)\n",
    "        x = self.decoder_conv(x)\n",
    "        x = x[:,:,:self.img_dims[-2], :self.img_dims[-1]]\n",
    "        if self.img_dims[0] == 1:\n",
    "            x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c6d09-51cb-41f2-a0e3-6bb74868e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBO(nn.Module):\n",
    "    def __init__(self, main_criterion, beta):\n",
    "        super().__init__()\n",
    "        self.main_criterion = main_criterion\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, x_rec, x_true, mu, sigma):\n",
    "        loss1 = self.main_criterion(x_rec, x_true)\n",
    "        loss2 = self.kl_gaussian_loss(mu, sigma)\n",
    "        loss = loss1 + self.beta * loss2\n",
    "        return loss      \n",
    "    \n",
    "    def kl_gaussian_loss(self, mu, sigma):\n",
    "        return 0.5 * torch.mean(sigma ** 2 + mu ** 2 - 2 * torch.log(sigma) - 1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41d991a-c462-4a0b-9d61-1dbe23a4521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from tensorboard_pytorch import TensorboardPyTorch\n",
    "\n",
    "def run_epoch(model, loaders, criterion, optim, writer, epoch, phase):\n",
    "    running_acc = 0.0\n",
    "    running_loss = 0.0\n",
    "    for x_true, _ in loaders[phase]:\n",
    "        x_true = x_true.to(device)\n",
    "        x_rec, mu, sigma = model(x_true)\n",
    "        loss = criterion(x_rec, x_true, mu, sigma)\n",
    "        if 'train' in phase:\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        running_loss += loss.item() * x_true.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(loaders[phase].dataset)\n",
    "    writer.log_scalar(f'Loss/{phase}', round(epoch_loss, 4), epoch + 1)\n",
    "    if 'test' in phase:\n",
    "        writer.log_reconstructions_visualize(model, loaders[phase], epoch)\n",
    "    \n",
    "    \n",
    "def simple_trainer(model, loaders, criterion, optim, writer, epoch_start, epoch_end):\n",
    "    for epoch in tqdm(range(epoch_start, epoch_end)):\n",
    "        model.train()\n",
    "        run_epoch(model, loaders, criterion, optim, writer, epoch, phase='train')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            run_epoch(model, loaders, criterion, optim, writer, epoch, phase='test')\n",
    "            \n",
    "\n",
    "def configure_optimizers(model, optim, weight_decay=1e-4, **optim_kwargs):\n",
    "    # separate out all parameters to those that will and won't experience regularizing weight decay\n",
    "    decay = set()\n",
    "    no_decay = set()\n",
    "    whitelist_weight_modules = (nn.Linear, nn.Conv1d, nn.Conv2d, nn.ConvTranspose2d)\n",
    "    blacklist_weight_modules = (nn.LayerNorm, nn.Embedding, nn.BatchNorm1d, nn.BatchNorm2d)\n",
    "    for mn, m in model.named_modules():\n",
    "        for pn, p in m.named_parameters():\n",
    "            fpn = '%s.%s' % (mn, pn) if mn else pn # full param name\n",
    "\n",
    "            if pn.endswith('bias'):\n",
    "                # all biases will not be decayed\n",
    "                no_decay.add(fpn)\n",
    "            elif pn.endswith('weight') and isinstance(m, whitelist_weight_modules):\n",
    "                # weights of whitelist modules will be weight decayed\n",
    "                decay.add(fpn)\n",
    "            elif pn.endswith('weight') and isinstance(m, blacklist_weight_modules):\n",
    "                # weights of blacklist modules will NOT be weight decayed\n",
    "                no_decay.add(fpn)\n",
    "\n",
    "    # special case the position embedding parameter in the root GPT module as not decayed\n",
    "    # no_decay.add('pos_emb')\n",
    "\n",
    "    # validate that we considered every parameter\n",
    "    param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "    inter_params = decay & no_decay\n",
    "    union_params = decay | no_decay\n",
    "    assert len(inter_params) == 0, \"parameters %s made it into both decay/no_decay sets!\" % (str(inter_params), )\n",
    "    assert len(param_dict.keys() - union_params) == 0, \"parameters %s were not separated into either decay/no_decay set!\" \\\n",
    "                                                % (str(param_dict.keys() - union_params), )\n",
    "\n",
    "    # create the pytorch optimizer object\n",
    "    optim_groups = [\n",
    "        {\"params\": [param_dict[pn] for pn in sorted(list(decay))], \"weight_decay\": weight_decay},\n",
    "        {\"params\": [param_dict[pn] for pn in sorted(list(no_decay))], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = optim(optim_groups, **optim_kwargs)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a0ab6-80af-4619-9d56-b43cc33d96b1",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86379d9b-e2e3-4436-a6a8-07ffa6adbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "IMG_DIMS = (3, 32, 32)\n",
    "\n",
    "encoder = Encoder(IMG_DIMS)\n",
    "decoder = Decoder(IMG_DIMS)\n",
    "model = ConvVAE(encoder, decoder, device).to(device)\n",
    "main_criterion = nn.MSELoss()\n",
    "criterion = ELBO(main_criterion, beta=1.0).to(device)\n",
    "optim = configure_optimizers(model, torch.optim.SGD, weight_decay=0.001, lr=0.01)\n",
    "# optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = TensorboardPyTorch(f'tensorboard/ConvVAE/cifar10/mainloss:mse_optim:sgd_lr:{0.01}_wd:{0.001}_epochs:{EPOCHS}/{date}', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93079c-a5bc-4c15-b527-2a510bff9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_trainer(model, loaders, criterion, optim, writer, epoch_start=0, epoch_end=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc7ea0-fdd7-4539-8959-79d166f50fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e755f651-8b44-4d1f-ac69-b289a8fa85de",
   "metadata": {},
   "source": [
    "# Denoising Autoencoders (DAE) (Dropout or Noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bab26-ff76-4e7b-bd87-df9788429388",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439f78f-3588-4452-b0ef-516e492c0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "IMG_DIMS = (1, 28, 28)\n",
    "\n",
    "encoder = Encoder(IMG_DIMS, nn.Dropout(0.2))\n",
    "decoder = Decoder(IMG_DIMS)\n",
    "model = ConvAutoEncoder(encoder, decoder).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = TensorboardPyTorch(f'tensorboard/convautoencoder_shorter/fmnist_noise:dropout:{0.2}/loss:bce_optim:sgd_lr:{0.01}_wd:{0.001}_epochs:{EPOCHS}/{date}', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7586cc9-4a7b-4aa9-89fb-8c2222f6be66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simple_trainer(model, loaders, criterion, optim, writer, epoch_start=0, epoch_end=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3403cc-60a4-4e11-9e0f-ef56504bdd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### how dropout works\n",
    "import matplotlib.pyplot as plt\n",
    "dropout = nn.Dropout(0.6)\n",
    "x_true = next(iter(loader_test))[0]\n",
    "plt.imshow(np.squeeze(dropout(x_true)[0].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa243d7c-3898-4db8-b88c-c7de1f374693",
   "metadata": {},
   "source": [
    "## Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afaccb-6f99-49b5-8fe6-30011cdaf963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn_like(tensor) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679c858-b1f9-4293-8501-d784a2425bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "IMG_DIMS = (1, 28, 28)\n",
    "\n",
    "encoder = Encoder(IMG_DIMS, GaussianNoise(std=0.2))\n",
    "decoder = Decoder(IMG_DIMS)\n",
    "model = ConvAutoEncoder(encoder, decoder).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = TensorboardPyTorch(f'tensorboard/convautoencoder_shorter/fmnist_noise:gaussian:{0.2}/loss:bce_optim:sgd_lr:{0.01}_wd:{0.001}_epochs:{EPOCHS}/{date}', device)\n",
    "\n",
    "simple_trainer(model, loaders, criterion, optim, writer, epoch_start=0, epoch_end=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129623a-882f-4a2f-88d9-2a44c2550b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tldl",
   "language": "python",
   "name": "tldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
